<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width,initial-scale=1.0" />
	<link href='https://fonts.googleapis.com/css?family=Sarpanch' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" href="normalize.css" />
	<link rel="stylesheet" href="styles.css" />
	<link rel="stylesheet" href="responsive.css" />
	<title>Digital Humanities</title>
</head>
<body>
	
	<h1><marquee>Potential Threats</marquee></h1>

	<img src="img/skull.gif" class="gif" id="gif-left" alt="Tech gif" />
	<img src="img/matrix.gif" class="gif" id="gif-right" alt="Tech gif" />

	<nav>
		<a href="index.html"><h3>HOME</h3></a>
		<a href="living_proof.html"><h3>LIVING PROOF</h3></a>
		<a href="threats.html"><h3>POTENTIAL THREATS</h3></a>
	</nav>
	<br>
	<div class="main">
		<div class="row">
			<img src="img/takeover.jpg" alt="Robots takeover" />
				<div>
				<p><span>AI takeover </span><br> Refers to a hypothetical scenario in which artificial intelligence (AI) becomes the dominant form of intelligence on Earth, with computers or robots effectively taking control of the planet away from the human race, and posing an existential risk which could wipe all people out.[1] Scenarios of this type may go by many other names, such as robot apocalypse, robot uprising, or cybernetic revolt. As computer and robotics technologies are advancing at an ever increasing rate, AI takeover is a growing concern. It has also been a major theme throughout science fiction for many decades.
				</p>
			</div>
		</div>
		<div class="row">
			<img src="img/recursion.jpg" alt="Robo recursion" />
			<div>
				<p><span>Recursive self-improvement</span><br> The speculative ability of a strong artificial intelligence computer program to program its own software, recursively. This is sometimes also referred to as Seed AI because if an AI were created with engineering capabilities that matched or surpassed those of its human creators, it would have the potential to autonomously improve the design of its constituent software and hardware. Having undergone these improvements, it would then be better able to find ways of optimizing its structure and improving its abilities further. It is speculated that over many iterations, such an AI would far surpass human cognitive abilities.
				</p>
			</div>
		</div>
		<div class="row">
			<img src="img/stephen.jpg" alt="Stephen Hawking" />
			<div>
				<p><span>Stephen Hawking:</span><br> Said in 2014 that "Success in creating AI would be the biggest event in human history. Unfortunately, it might also be the last, unless we learn how to avoid the risks." Hawking believes that in the coming decades, AI could offer "incalculable benefits and risks" such as "technology outsmarting financial markets, out-inventing human researchers, out-manipulating human leaders, and developing weapons we cannot even understand."
				</p>
			</div>
		</div>
		<div class="row">
			<img src="img/fli.jpg" alt="FLI" />
			<div>
				<p><span>The Future of Life Institute</span><br> A volunteer-run research and outreach organization in the Boston area that works to mitigate existential risks facing humanity, particularly the Existential risk of artificial general intelligence (AI). It was founded by MIT cosmologist Max Tegmark and Skype co-founder Jaan Tallinn among others, and includes cosmologist Stephen Hawking and entrepreneur Elon Musk among others on the board of advisers.
				</p>
			</div>
		</div>

		<span>Source: https://en.wikipedia.org/wiki/AI_takeover</span>

	</div>

</body>
</html>